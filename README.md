# Day-Night-Image-Translations-using-CycleGAN
Day-Night Image Translations using CycleGAN

<h2 style='color:lightgreen'> Introduction </h2>

    Paper Link : https://www.cs.cmu.edu/~junyanz/projects/CycleGAN/CycleGAN.pdf

    Cycle GANs provide the approach to translate an image from source domain X to target domain Y in absence of paired examples. The goal is to learn a mapping G: X-> Y , and inverse mapping F: Y -> X , and introduce a cycle consistancy loss to enforce F(G(X)) = X and G(F(Y_hat)) = Y_hat. 

    The problem that Cycle GANs address can be classified as Image to Image translation. While there are other methods that address the problem with image- target pairs, obtaining these pairs is difficult and expensive. This method is applied for the tasks of style transfer, object transfiguration, and attribute transfer and claims to outperform baseline approaches.



<h2 style='color:lightgreen'>Formulation</h2>

    Our goal is to learn two mapping functions G,F over two domains X,Y ; such that G: X -> Y and F : Y -> X. We can think of X as set of pictures, and Y as the set of paintings, for the task of converting Pictures to Paintings. The functions G and F are Generators. 

    We also have adverserial discriminators Dx and Dy, where Dx has the task to discriminating between images from set X (pictures) and set of images generated by F(Y)/X_hat (i.e the image generated by the inverse mapping Generator F). Similarly Dy has the task to discriminating between images from set Y (Paintings) and set of images generated by G(X)/Y_hat  (i.e the image generated by the generator G) .

    We guide the training of the GAN using an objective that has two components : 
    1) Adverserial loss: For mapping of input domain to target domain, and vice versa.
    2) Cycle Consistency loss:  For enforcing cycle consistency so that F(G(X)) = X and G(F(Y)) = Y . 


<h2 style='color:lightgreen'>Losses</h2>

    1) Adverserial loss : 

    Loss for GAN G: LGAN(G,DY ,X,Y ) =Ey∼pdata (y)[log DY (y)] + Ex∼pdata (x)[log(1 −DY (G(x))]

    Loss for GAN F : LGAN(F,DX ,Y,X ) =Ex∼pdata (x)[log Dx (x)] + Ey∼pdata (y)[log(1 −Dx (F(y))]

    Where G tries to generate images similar to domain Y, and Dy tries to to discriminate between generated images and original images.
    Similarly, F tries to generate images similar to domain X, and Dx tries to to discriminate between generated images and original images.

    2) Cycle Consistency loss: The network can learn to map input images to some random set permutations in the output domain, which can match the target distribution.Hence using only a adverserial loss would not guarantee a desired and consistant mapping. Hence we apply Cycle consistance loss to enforce this behavour. 

    Forward Cycle Consistancy : x → G(x) → F(G(x)) ≈ x ; where x is the input image domain.

    Backward Cycle Consistancy : y → F(y) → G(F(y)) ≈ y ; where y is the target image domain.

    Cycle loss : Lcyc(G,F) =Ex∼pdata(x) [‖F(G(x)) −x‖1] + Ey∼pdata(y) [‖G(F(y)) −y‖1]


<h2 style='color:lightgreen'>Objective</h2>
 

    Hence the full loss is: 

    L(G,F,DX ,DY) = LGAN(G,DY ,X,Y ) + LGAN(F,DX ,Y,X) + λ * Lcyc(G,F)

<h2 style='color:lightgreen'>Implementation</h2>

    1) Architecture : Used the generator architecture from Johnson et al, with instance normalization. The discriminator uses a PatchGAN, which classifies wheather 70*70 patch in the image is real or fake.
    2) Training Detail: 
       a) Adverserial Loss : Replace the Log-likelyhood adverserial loss with the Least Square loss, as it is more stable during training.
       b) Total loss : Used the cycle consistency loss weighting parameter Lambda  = 10 .
       c) Optimization : Used Adam optimizer with LR = 0.0002 for first 100 epoch, linealy decaying into 0 in next 100 epochs. (i.e total 200 epochs)
       d) Batch Size : 1 
       c) Training updates: Used history of training images for updating Dx and Dy, using a buffer that stores 50 previously generated images . This reduces model oscillations (from strivastava et al).
       This notebook uses Cycle GANs to trying to convert high resolution Day cityscapes images to Night images and vice versa. The dataset consists of high resolution Day and Night images. Cycle GANs allows us to use the dataset without any explicit image-target image pairs, by using cycle consistancy loss to ensure that the images retain the semantic and structural components. Hence Cycle GAN builds on top of Pix2Pix GANs, with an additional Cycle Consistency loss.

<h2 style='color:lightgreen'>Sample Outputs</h2>


Day -> Night

<img width="654" alt="Screenshot 2024-11-18 at 3 16 43 AM" src="https://github.com/user-attachments/assets/77f4ec34-20c9-4c89-80e6-7c8cf0136cd5">


Night -> Day

<img width="651" alt="Screenshot 2024-11-18 at 3 17 58 AM" src="https://github.com/user-attachments/assets/ed5bf0d4-cb44-4f76-a095-b91fd8b8dad9">


Day -> Night -> Day

<img width="814" alt="cyclegan1" src="https://github.com/user-attachments/assets/1b154145-fa24-4de0-b14c-2b06971c7c7a"> 

    




